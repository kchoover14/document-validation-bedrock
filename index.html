<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.9.23">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kara C. Hoover">

<title>LLM-Powered Document Validation and Auditing via AWS Bedrock</title>
<style>
/* Default styles provided by pandoc.
** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
*/
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="document-validation-bedrock_files/libs/clipboard/clipboard.min.js"></script>
<script src="document-validation-bedrock_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="document-validation-bedrock_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="document-validation-bedrock_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="document-validation-bedrock_files/libs/quarto-html/popper.min.js"></script>
<script src="document-validation-bedrock_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="document-validation-bedrock_files/libs/quarto-html/anchor.min.js"></script>
<link href="document-validation-bedrock_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="document-validation-bedrock_files/libs/quarto-html/quarto-syntax-highlighting-076ecbd647e1f0418c5051713cd9b730.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="document-validation-bedrock_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="document-validation-bedrock_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="document-validation-bedrock_files/libs/bootstrap/bootstrap-fdc35ccebf6ef883c9ad23e25989f106.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="blues quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#executive-summary" id="toc-executive-summary" class="nav-link active" data-scroll-target="#executive-summary">Executive Summary</a></li>
  <li><a href="#research-question" id="toc-research-question" class="nav-link" data-scroll-target="#research-question">Research Question</a></li>
  <li><a href="#research-answers" id="toc-research-answers" class="nav-link" data-scroll-target="#research-answers">Research Answers</a>
  <ul class="collapse">
  <li><a href="#prompt-design-determines-reliability" id="toc-prompt-design-determines-reliability" class="nav-link" data-scroll-target="#prompt-design-determines-reliability">Prompt Design Determines Reliability</a></li>
  <li><a href="#semantic-anomaly-detection-what-rule-based-systems-cannot-do" id="toc-semantic-anomaly-detection-what-rule-based-systems-cannot-do" class="nav-link" data-scroll-target="#semantic-anomaly-detection-what-rule-based-systems-cannot-do">Semantic Anomaly Detection: What Rule-Based Systems Cannot Do</a></li>
  <li><a href="#hybrid-architecture-optimizes-cost-and-coverage" id="toc-hybrid-architecture-optimizes-cost-and-coverage" class="nav-link" data-scroll-target="#hybrid-architecture-optimizes-cost-and-coverage">Hybrid Architecture Optimizes Cost and Coverage</a></li>
  </ul></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next Steps</a></li>
  <li><a href="#study-design" id="toc-study-design" class="nav-link" data-scroll-target="#study-design">Study Design</a></li>
  <li><a href="#project-resources" id="toc-project-resources" class="nav-link" data-scroll-target="#project-resources">Project Resources</a></li>
  <li><a href="#tools-technologies" id="toc-tools-technologies" class="nav-link" data-scroll-target="#tools-technologies">Tools &amp; Technologies</a></li>
  <li><a href="#expertise" id="toc-expertise" class="nav-link" data-scroll-target="#expertise">Expertise</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">LLM-Powered Document Validation and Auditing via AWS Bedrock</h1>
  <div class="quarto-categories">
    <div class="quarto-category">AWS</div>
    <div class="quarto-category">Bedrock</div>
    <div class="quarto-category">document validation</div>
    <div class="quarto-category">fraud detection</div>
    <div class="quarto-category">prompt engineering</div>
    <div class="quarto-category">lambda</div>
    <div class="quarto-category">serverless</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Kara C. Hoover </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="executive-summary" class="level2">
<h2 class="anchored" data-anchor-id="executive-summary">Executive Summary</h2>
<p><strong>Problem:</strong> Traditional identity document validation pipelines rely on OCR for text extraction followed by rule-based logic checks. This approach extracts text without understanding semantics, requires explicit programming for every validation scenario, and fails on novel or non-standard document layouts – missing exactly the kinds of inconsistencies that signal fraud.</p>
<p><strong>Approach:</strong> Built a proof-of-concept serverless auditing pipeline using Claude 3 Haiku via AWS Bedrock to evaluate whether LLMs can detect fraudulent entries in document metadata before they are committed to a permanent record. The system simulates a biometric document ingestion workflow: documents are scanned upstream (via OCR) and their metadata – scores, flags, and field values – is stored as JSON records in a PostgreSQL database. A Lambda function retrieves unaudited records and passes them to Claude, acting as a “Senior Forensic Document Auditor,” which returns a structured PASS/FAIL verdict with reasoning. Ten synthetic audit log entries (8 valid, 2 flagged as malicious) were processed using three prompting strategies (minimal zero-shot, schema-driven, chain-of-thought) and evaluated on structured output reliability, response time, and anomaly detection rate.</p>
<p><strong>Implications:</strong> Schema-driven prompting is an excellent design choice for production: it achieved 100% structured output reliability and 100% anomaly detection at 1.6s average response time. LLMs catch semantic violations that OCR cannot detect (e.g., expiration dates that precede issue dates, future-dated documents, or formatting inconsistencies), but they are costly and not suitable for all cases. A hybrid architecture is recommended: fast OCR handles bulk volume and LLM handles flagged cases (10–20% of documents) where semantic validation justifies the 8x cost premium.</p>
<p><strong>Significance:</strong> As document fraud becomes more sophisticated, rule-based validation systems are increasingly insufficient. This project demonstrates a scalable, cost-aware integration pattern for deploying LLM semantic reasoning within enterprise document workflows – applicable to identity verification, compliance screening, and any domain requiring explainable anomaly detection at scale. While this project focused on identity documents, the hybrid approach is transferable to other document types requiring validation (e.g., legal papers, vaccination and medical records).</p>
<p><strong>Key Findings</strong></p>
<ul>
<li>Prompt design is the most important variable in production reliability</li>
<li>Schema-driven prompting achieved 100% JSON parse success and 100% anomaly detection</li>
<li>LLMs detected semantic anomalies that are structurally invisible to OCR</li>
<li>Cost analysis at scale supports selective deployment: processing 10% of documents through LLM review reduces monthly cost by 70% relative to all-LLM processing while retaining 95%+ of semantic anomaly detection</li>
</ul>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Built to explore whether LLMs can close the semantic gap in traditional identity document verification pipelines. Produces a validated hybrid architecture recommendation with cost and performance benchmarks – directly applicable to enterprise fraud screening, compliance workflows, and identity risk management systems.</p>
</div>
</div>
</div>
<hr>
</section>
<section id="research-question" class="level2">
<h2 class="anchored" data-anchor-id="research-question">Research Question</h2>
<p>Can large language models augment traditional rule-based document validation by detecting semantic anomalies that static logic checks miss, and if so, which prompting strategy optimizes the reliability-cost-speed trade-off for serverless production deployment?</p>
<hr>
</section>
<section id="research-answers" class="level2">
<h2 class="anchored" data-anchor-id="research-answers">Research Answers</h2>
<section id="prompt-design-determines-reliability" class="level3">
<h3 class="anchored" data-anchor-id="prompt-design-determines-reliability">Prompt Design Determines Reliability</h3>
<p>The three prompting strategies produced dramatically different results despite using the same model and the same records. Minimal zero-shot prompting – brief instructions, no schema – achieved only 67% JSON parse success and detected no anomalies in the test cases. Schema-driven prompting, which provided an explicit JSON schema and specified validation requirements, achieved 100% parse success and 100% anomaly detection at a mean response time of 1.6 seconds. Chain-of-thought prompting, which required the model to reason step by step before rendering a verdict, also achieved 100% on both metrics but at 2.3 seconds – a 44% latency increase with no accuracy gain.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Strategy</th>
<th>JSON Success</th>
<th>Avg Time</th>
<th>Anomaly Detection</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Minimal</td>
<td>67%</td>
<td>1.4s</td>
<td>0%</td>
</tr>
<tr class="even">
<td>Schema-Driven</td>
<td>100%</td>
<td>1.6s</td>
<td>100%</td>
</tr>
<tr class="odd">
<td>Chain-of-Thought</td>
<td>100%</td>
<td>2.3s</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p><strong>Interpretation:</strong> Schema-driven prompting is the production design choice. The investment is in prompt engineering, not model selection – vague instructions reliably produce inconsistent outputs regardless of model capability.</p>
</section>
<section id="semantic-anomaly-detection-what-rule-based-systems-cannot-do" class="level3">
<h3 class="anchored" data-anchor-id="semantic-anomaly-detection-what-rule-based-systems-cannot-do">Semantic Anomaly Detection: What Rule-Based Systems Cannot Do</h3>
<p>The clearest demonstration of LLM value came from the date anomaly test case. The metadata record contained an issue date in the future (06/20/2025) and an expiration date that preceded the issue date (06/20/2024). A rule-based system would require an explicitly programmed check to catch this; the LLM identifies it from semantic understanding of what document dates mean – no rule required.</p>
<p>The schema-driven response returned structured JSON identifying both violations: issue date in the future, expiration date before issuance, and a composite “date logic violation” flag – plus a confidence level of “low” and a rejection recommendation. This is the system prompt doing the work: Claude was instructed to act as a Senior Forensic Document Auditor checking for logical inconsistencies, and the schema-driven format ensured the output was reliably parseable.</p>
<p>The formatting inconsistency test case showed a complementary strength: the chain-of-thought strategy identified that a record with a lowercase name, three different date format conventions, and hyphenated ID numbers was anomalous in context – without requiring any pre-programmed rules about format standards. It normalized the data, explained its reasoning in natural language, and recommended human review rather than automatic rejection, which is the appropriate response for formatting irregularities that may have reasonable explanations.</p>
<p><strong>Interpretation:</strong> LLMs add value by performing the semantic reasoning layer that rule-based systems architecturally cannot provide. The value is concentrated in records flagged as suspicious – a small subset of the ingestion stream.</p>
</section>
<section id="hybrid-architecture-optimizes-cost-and-coverage" class="level3">
<h3 class="anchored" data-anchor-id="hybrid-architecture-optimizes-cost-and-coverage">Hybrid Architecture Optimizes Cost and Coverage</h3>
<p>At $0.008 per document, LLM processing costs 8x more than traditional rule-based processing at $0.001 per document. At high volume, all-LLM processing is not viable – $8,000 per million documents versus $1,000 for rule-based-only. The cost case for a hybrid architecture is straightforward.</p>
<p><strong>Figure 1. Prompt strategy performance comparison: JSON parse success, average response time, and anomaly detection rate across minimal, schema-driven, and chain-of-thought approaches.</strong></p>
<p><img src="bedrock_analysis_comparison.png" class="img-fluid"></p>
<p>In the recommended architecture, upstream OCR scans the full document stream and a rule-based filter passes clean records directly to the database (estimated 80–90% of volume), routing only flagged records to Lambda for LLM analysis. The LLM performs semantic validation and generates natural language explanations for human reviewers. At 100K documents per month, this architecture costs approximately $170/month – compared to $800 for all-LLM and $100 for rule-based-only – while retaining semantic detection capability for the 10% of documents where it matters.</p>
<p><strong>Interpretation:</strong> The hybrid pipeline uses rule-based processing for faster and cheaper bulk throughput and LLMs for semantic reasoning on ambiguous cases. The cost premium is justified when the decision stakes are highest (fraud versus reasonable errors).</p>
<hr>
</section>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>The current proof-of-concept used synthetic metadata records with controlled anomalies. Production validation would require testing against a real document corpus with known ground-truth labels to establish precision and recall for anomaly detection across document types and jurisdictions. Key open questions include: how performance degrades on genuinely novel record patterns the model has not encountered; how to handle hallucination risk in production (the model may generate plausible but incorrect reasoning); and whether fine-tuning on domain-specific audit data improves reliability beyond prompt engineering alone.</p>
<p>A significant infrastructure challenge identified during development is Lambda-to-RDS networking. Connecting a Lambda function outside a VPC to a publicly accessible RDS instance produces <code>InterfaceError</code> timeouts due to AWS internal routing overhead. The correct production architecture places Lambda inside the same private VPC as RDS, with a NAT Gateway or VPC Endpoints to maintain Bedrock API access while keeping database traffic off the public internet.</p>
<p>The hybrid architecture also assumes a stable confidence signal as the routing criterion. In practice, calibrating the threshold – deciding what fraction of records gets LLM review – requires empirical data on the false negative rate of rule-based-only processing in the specific operational context.</p>
<hr>
</section>
<section id="study-design" class="level2">
<h2 class="anchored" data-anchor-id="study-design">Study Design</h2>
<p><strong>Data Source:</strong> Synthetic audit log records generated for this proof-of-concept using the <code>faker</code> library. Ten JSON records inserted into a PostgreSQL (RDS) <code>audit_logs</code> table representing biometric document scans: 8 with valid scores (0.95) and 2 with low scores (0.30) simulating flagged/malicious entries. No real identity documents or images were used; the LLM operates on structured metadata, not raw images.</p>
<p><strong>Data Handling:</strong> Unaudited records (where <code>ai_status IS NULL</code>) were retrieved from RDS and passed as JSON payloads to the Bedrock API. Each record included <code>user_id</code>, <code>score</code>, and <code>doc_type</code>. Claude was instructed via system prompt to act as a Senior Forensic Document Auditor, check for logical inconsistencies, and return <code>{"status": "PASS"/"FAIL", "reasoning": "..."}</code>. Results were written back to the <code>ai_status</code> and <code>ai_reasoning</code> columns. Audit outcomes were visualized as a bar chart of PASS/FAIL counts.</p>
<p><strong>Analytical Approach:</strong></p>
<ol type="1">
<li>Initialized PostgreSQL schema (<code>schema.sql</code>) with <code>audit_logs</code> table storing <code>user_id</code>, <code>document_type</code>, <code>ai_status</code>, <code>ai_reasoning</code>, and <code>raw_data</code> (JSONB)</li>
<li>Generated 10 synthetic records using <code>faker</code> and inserted via <code>pg8000.native</code>; 2 records seeded with low verification scores (0.30) to simulate fraud cases</li>
<li>Built Lambda function (Python 3.12) to retrieve unaudited records from RDS and invoke Claude 3 Haiku via Bedrock with a forensic auditor system prompt</li>
<li>Tested three prompting strategies varying in structure: minimal zero-shot, schema-driven zero-shot, zero-shot chain-of-thought</li>
<li>Evaluated each strategy on JSON parse success, response time, and PASS/FAIL accuracy against known ground truth</li>
<li>Modeled cost at scale under three architectures: rule-based only, LLM-only, hybrid</li>
<li>Derived hybrid pipeline architecture recommendation balancing cost, latency, and semantic coverage; documented VPC/networking lessons learned for Lambda-to-RDS connectivity</li>
</ol>
<hr>
</section>
<section id="project-resources" class="level2">
<h2 class="anchored" data-anchor-id="project-resources">Project Resources</h2>
<p><strong>Repository:</strong> <a href="https://github.com/kchoover14/document-validation-bedrock">github.com/kchoover14/document-validation-bedrock</a></p>
<p><strong>Data:</strong> Synthetic audit log records generated via the <code>faker</code> library – no real identity documents used. No external data source.</p>
<p><strong>Code:</strong></p>
<ul>
<li><code>prompt engineering via lambda.ipynb</code> – main pipeline: RDS connection, mock data generation, Bedrock invocation, audit results, visualization</li>
<li><code>mockDatabase.ipynb</code> – standalone mock data generator showing synthetic record construction</li>
<li><code>schema.sql</code> – PostgreSQL table definition for <code>audit_logs</code></li>
<li><code>system_prompt.txt</code> – forensic auditor system prompt used with Claude 3 Haiku</li>
</ul>
<p><strong>Project Artifacts:</strong></p>
<ul>
<li>Figures (n=1)</li>
</ul>
<p><strong>Environment:</strong></p>
<ul>
<li><code>requirements.txt</code> – install pinned Python package versions with <code>pip install -r requirements.txt</code></li>
</ul>
<p><strong>License:</strong></p>
<ul>
<li>Code and scripts © Kara C. Hoover, licensed under the <a href="LICENSE">MIT License</a>.</li>
<li>Data, figures, and written content © Kara C. Hoover, licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>.</li>
</ul>
<hr>
</section>
<section id="tools-technologies" class="level2">
<h2 class="anchored" data-anchor-id="tools-technologies">Tools &amp; Technologies</h2>
<p><strong>Languages:</strong> Python 3.12</p>
<p><strong>Tools:</strong> AWS Bedrock | AWS Lambda | AWS RDS (PostgreSQL 17)</p>
<p><strong>Packages:</strong> pg8000 | boto3 | faker | pandas | matplotlib</p>
<hr>
</section>
<section id="expertise" class="level2">
<h2 class="anchored" data-anchor-id="expertise">Expertise</h2>
<p><strong>Domain Expertise:</strong> prompt engineering | LLM integration | serverless architecture | document fraud detection | cost-performance trade-off analysis | AWS Bedrock | AWS Lambda | PostgreSQL</p>
<p><strong>Transferable Expertise:</strong> This project demonstrates the ability to design and evaluate AI integration architectures under real-world constraints – not just whether a technology works, but when, for whom, and at what cost. The hybrid pipeline recommendation reflects a pattern-recognition skill applicable to any enterprise context where AI capability must be balanced against operational cost, latency, and explainability requirements.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>